#!/usr/bin/env python3
import argparse
import csv
import ctypes
import json
import os
import time
from pathlib import Path
from typing import Dict, List, Optional, Tuple

os.environ.setdefault("ORT_DISABLE_CPU_AFFINITY", "1")

import cv2
import numpy as np
import onnxruntime as ort

import sys


def _repo_root() -> Path:
    return Path(__file__).resolve().parents[1]


sys.path.insert(0, str(_repo_root()))
from acl_predictor import AclPredictor  # noqa: E402
from scripts.common_vis_utils import (  # noqa: E402
    _annotate_side_by_side,
    _make_side_by_side,
    preprocess_image,
    draw_rotated_boxes,
)


def _parse_hw(s: str) -> Tuple[int, int]:
    parts = [p.strip() for p in s.split(",") if p.strip()]
    if len(parts) != 2:
        raise ValueError(f"invalid input-hw: {s}")
    return int(parts[0]), int(parts[1])


def _stat(vals: List[float]) -> Dict[str, float]:
    if not vals:
        return {"mean": 0.0, "p50": 0.0, "p90": 0.0, "max": 0.0, "min": 0.0}
    arr = np.asarray(vals, dtype=np.float64)
    return {
        "mean": float(np.mean(arr)),
        "p50": float(np.percentile(arr, 50)),
        "p90": float(np.percentile(arr, 90)),
        "max": float(np.max(arr)),
        "min": float(np.min(arr)),
    }


def _safe_float(s: str) -> Optional[float]:
    try:
        v = float(s)
        if np.isfinite(v):
            return v
    except Exception:
        pass
    return None


def main() -> int:
    root = _repo_root()
    p = argparse.ArgumentParser()
    p.add_argument("--work-dir", required=True, help="Directory generated by run_om_only_with_cached_ort.py")
    p.add_argument("--om", required=True, help="OM path for single-image benchmark")
    p.add_argument("--image-dir", default=str(root / "images"))
    p.add_argument("--input-hw", default="672,1024")
    p.add_argument("--onnx", default=str(root / "ascend_c_onnx" / "end2end_simp.only_dets_labels.ort_tmp.onnx"))
    p.add_argument("--custom-ops", default=str(root / "onnxruntime_mmrotate_ops" / "build" / "libonnxruntime_mmrotate_ops.so"))
    p.add_argument("--ort-intra-op-threads", type=int, default=max(1, (os.cpu_count() or 4) // 2))
    p.add_argument("--ort-inter-op-threads", type=int, default=1)
    p.add_argument("--device-id", type=int, default=0)
    p.add_argument("--score-thr", type=float, default=0.3)
    p.add_argument("--single-image", default="", help="Single image for ORT/OM benchmark. Default first row.")
    p.add_argument("--bench-warmup", type=int, default=1)
    p.add_argument("--bench-iters", type=int, default=3)
    args = p.parse_args()

    work_dir = Path(args.work_dir).resolve()
    summary_om_csv = work_dir / "summary_om_only.csv"
    if not summary_om_csv.is_file():
        raise SystemExit(f"missing: {summary_om_csv}")
    om_path = Path(args.om).resolve()
    if not om_path.is_file():
        raise SystemExit(f"missing om: {om_path}")

    image_dir = Path(args.image_dir).resolve()
    hw = _parse_hw(args.input_hw)

    rows_om = list(csv.DictReader(summary_om_csv.open("r", encoding="utf-8")))
    if not rows_om:
        raise SystemExit(f"no rows in {summary_om_csv}")

    # ORT session
    custom_ops_so = Path(args.custom_ops).resolve()
    ctypes.CDLL(str(custom_ops_so))
    so = ort.SessionOptions()
    so.intra_op_num_threads = int(args.ort_intra_op_threads)
    so.inter_op_num_threads = int(args.ort_inter_op_threads)
    so.execution_mode = ort.ExecutionMode.ORT_SEQUENTIAL
    so.register_custom_ops_library(str(custom_ops_so))
    ort_sess = ort.InferenceSession(str(Path(args.onnx).resolve()), sess_options=so, providers=["CPUExecutionProvider"])
    input_name = ort_sess.get_inputs()[0].name

    out_rows: List[Dict[str, str]] = []
    ort_lat_ms: List[float] = []
    om_lat_ms: List[float] = []

    for r in rows_om:
        image_name = r["image"]
        stem = Path(image_name).stem
        per_dir = work_dir / stem
        dets_om_p = per_dir / "dets_om.npy"
        labels_om_p = per_dir / "labels_om.npy"
        if not dets_om_p.is_file() or not labels_om_p.is_file():
            continue

        img = cv2.imread(str(image_dir / image_name))
        if img is None:
            continue
        print(f"[ORT] start image={image_name}", flush=True)
        x, vis_base = preprocess_image(img, hw)
        x = x.astype(np.float32)

        t0 = time.perf_counter()
        dets_ort, labels_ort = ort_sess.run(["dets", "labels"], {input_name: x})
        t1 = time.perf_counter()
        ort_ms = (t1 - t0) * 1000.0
        ort_lat_ms.append(ort_ms)
        print(f"[ORT] done image={image_name} ort_ms={ort_ms:.3f}", flush=True)

        dets_ort = np.asarray(dets_ort)
        labels_ort = np.asarray(labels_ort)
        dets_om = np.asarray(np.load(dets_om_p))
        labels_om = np.asarray(np.load(labels_om_p))

        np.save(per_dir / "dets_ort.npy", dets_ort)
        np.save(per_dir / "labels_ort.npy", labels_ort)

        d = np.abs(dets_ort.astype(np.float32) - dets_om.astype(np.float32))
        dets_max_abs = float(np.max(d))
        dets_mean_abs = float(np.mean(d))
        dets_num_diff_gt_1e_3 = int(np.sum(d > 1e-3))
        labels_neq = int(np.sum(labels_ort.astype(np.int64) != labels_om.astype(np.int64)))

        vis_ort = draw_rotated_boxes(vis_base, dets_ort, labels_ort, float(args.score_thr))
        vis_om = draw_rotated_boxes(vis_base, dets_om, labels_om, float(args.score_thr))
        side = _make_side_by_side(vis_ort, vis_om)
        side = _annotate_side_by_side(side, "ORT", "NPU(OM)")
        cv2.imwrite(str(per_dir / "vis_input.jpg"), vis_base)
        cv2.imwrite(str(per_dir / "vis_ort.jpg"), vis_ort)
        cv2.imwrite(str(per_dir / "vis_om.jpg"), vis_om)
        cv2.imwrite(str(per_dir / "vis_side_by_side.jpg"), side)

        om_ms = _safe_float(r.get("om_ms", ""))
        if om_ms is not None:
            om_lat_ms.append(om_ms)

        out_rows.append(
            {
                "image": image_name,
                "om_ms": r.get("om_ms", "N/A"),
                "ort_ms": f"{ort_ms:.3f}",
                "speedup_ort_vs_om": (
                    f"{(om_ms / ort_ms):.4f}" if (om_ms is not None and ort_ms > 0) else "N/A"
                ),
                "dets_max_abs": f"{dets_max_abs:.6g}",
                "dets_mean_abs": f"{dets_mean_abs:.6g}",
                "dets_num_diff_gt_1e-3": str(dets_num_diff_gt_1e_3),
                "labels_neq": str(labels_neq),
            }
        )

    out_csv = work_dir / "summary_ort_vs_om.csv"
    with out_csv.open("w", newline="", encoding="utf-8") as f:
        w = csv.DictWriter(
            f,
            fieldnames=[
                "image",
                "om_ms",
                "ort_ms",
                "speedup_ort_vs_om",
                "dets_max_abs",
                "dets_mean_abs",
                "dets_num_diff_gt_1e-3",
                "labels_neq",
            ],
        )
        w.writeheader()
        for row in out_rows:
            w.writerow(row)

    # single-image benchmark (both ORT and OM)
    bench_image = str(args.single_image).strip() or (out_rows[0]["image"] if out_rows else rows_om[0]["image"])
    bench_img = cv2.imread(str(image_dir / bench_image))
    if bench_img is None:
        raise SystemExit(f"failed to read benchmark image: {bench_image}")
    bench_x, _ = preprocess_image(bench_img, hw)
    bench_x = bench_x.astype(np.float32)

    predictor = AclPredictor(model_path=str(om_path), device_id=int(args.device_id), do_finalize=True)
    warmup = max(0, int(args.bench_warmup))
    iters = max(1, int(args.bench_iters))

    for _ in range(warmup):
        ort_sess.run(["dets", "labels"], {input_name: bench_x})
        predictor.run(bench_x)

    ort_bench_ms: List[float] = []
    om_bench_ms: List[float] = []
    for _ in range(iters):
        t0 = time.perf_counter()
        ort_sess.run(["dets", "labels"], {input_name: bench_x})
        t1 = time.perf_counter()
        ort_bench_ms.append((t1 - t0) * 1000.0)

        t2 = time.perf_counter()
        predictor.run(bench_x)
        t3 = time.perf_counter()
        om_bench_ms.append((t3 - t2) * 1000.0)

    ort_stat = _stat(ort_bench_ms)
    om_stat = _stat(om_bench_ms)
    report = {
        "work_dir": str(work_dir),
        "counts": {
            "images_from_om_summary": len(rows_om),
            "images_compared": len(out_rows),
        },
        "aggregate_latency_ms": {
            "om_from_summary": _stat(om_lat_ms),
            "onnx_from_run": _stat(ort_lat_ms),
        },
        "aggregate_compare": {
            "ort_over_om_ratio_by_mean": (
                float(_stat(ort_lat_ms)["mean"] / _stat(om_lat_ms)["mean"]) if om_lat_ms else None
            ),
            "om_fps_from_mean": (float(1000.0 / _stat(om_lat_ms)["mean"]) if om_lat_ms else None),
            "onnx_fps_from_mean": (float(1000.0 / _stat(ort_lat_ms)["mean"]) if ort_lat_ms else None),
        },
        "single_image_benchmark": {
            "image": bench_image,
            "warmup": warmup,
            "iters": iters,
            "onnx": {
                **ort_stat,
                "fps_from_mean": float(1000.0 / ort_stat["mean"]) if ort_stat["mean"] > 0 else 0.0,
            },
            "om": {
                **om_stat,
                "fps_from_mean": float(1000.0 / om_stat["mean"]) if om_stat["mean"] > 0 else 0.0,
            },
            "onnx_over_om_ratio_by_mean": (
                float(ort_stat["mean"] / om_stat["mean"]) if om_stat["mean"] > 0 else None
            ),
        },
        "artifacts": {
            "summary_om_only_csv": str(summary_om_csv),
            "summary_ort_vs_om_csv": str(out_csv),
        },
    }
    report_path = work_dir / "report_ort_vs_om.json"
    report_path.write_text(json.dumps(report, indent=2, ensure_ascii=False), encoding="utf-8")
    print(json.dumps(report, indent=2, ensure_ascii=False))
    print(str(report_path))
    return 0


if __name__ == "__main__":
    raise SystemExit(main())
